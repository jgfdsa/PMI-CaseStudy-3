{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling of the store's sales through their surroundings.\n",
    "## Author: Gregorio Ferreira - ferreiradesajg@gmail.com\n",
    "\n",
    "### Document description:\n",
    "This notebook contains the steps followed to pre-process and extract the target variables to train the models considering the sales history of each of the stores under consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading prepared data and necessary environment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from collections import Counter\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "os.chdir('C:\\\\Users\\\\plgrfer\\\\Documents\\\\GitHub\\\\PMI-CaseStudy-3')\n",
    "\n",
    "sales = pd.read_csv(\"./result dataset/stores_sales.csv\",\n",
    "                     index_col=0)\n",
    "\n",
    "## Target variables\n",
    "#['store_code', 'count_non_na', 'trim_mean_01', 'trim_mean_02', 'mean',\n",
    "#       'min', 'max', 'count_non_na_class', 'trim_mean_01_class',\n",
    "#       'trim_mean_02_class', 'mean_class', 'min_class', 'max_class']\n",
    "\n",
    "## Selecting the target variables to analyze\n",
    "predictor = sales[['trim_mean_01']]\n",
    "predictor.columns = ['predictor']\n",
    "\n",
    "## loading my surroundings\n",
    "my_surr = pd.read_csv(\"C:/Users/plgrfer/Google Drive/PMI/UseCase_3_Datasets/result dataset/surroundings_count.csv\",\n",
    "                     index_col=0)\n",
    "\n",
    "## merging features and targets\n",
    "mydata = pd.merge(my_surr, predictor,  how='inner', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For this use case, I am considering the ' trim_mean_01' target variable to calculate the feature importance. The idea is to demonstrate the workflow, techniques and steps to analyze the data, rather than to focus on the optimization and best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
